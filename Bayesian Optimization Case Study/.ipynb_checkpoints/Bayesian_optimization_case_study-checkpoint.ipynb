{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNK7vbHo-KYU"
   },
   "source": [
    "## Bayesian methods of hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlFdvPwF-KYW"
   },
   "source": [
    "In addition to the random search and the grid search methods for selecting optimal hyperparameters, we can use Bayesian methods of probabilities to select the optimal hyperparameters for an algorithm.\n",
    "\n",
    "In this case study, we will be using the BayesianOptimization library to perform hyperparmater tuning. This library has very good documentation which you can find here: https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "You will need to install the Bayesian optimization module. Running a cell with an exclamation point in the beginning of the command will run it as a shell command — please do this to install this module from our notebook in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pssx080d-Ulf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from bayesian-optimization) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from bayesian-optimization) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from bayesian-optimization) (1.23.5)\n",
      "Collecting colorama>=0.4.6\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
      "Installing collected packages: colorama, bayesian-optimization\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.5\n",
      "    Uninstalling colorama-0.4.5:\n",
      "      Successfully uninstalled colorama-0.4.5\n",
      "Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n"
     ]
    }
   ],
   "source": [
    "! pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.1.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 12.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\terry\\anaconda3\\lib\\site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\terry\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2-cp39-cp39-win_amd64.whl (101.0 MB)\n",
      "     ------------------------------------- 101.0/101.0 MB 16.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\terry\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\terry\\anaconda3\\lib\\site-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\terry\\anaconda3\\lib\\site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\terry\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\terry\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2022.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\terry\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T16:39:09.312682Z",
     "start_time": "2019-04-22T16:39:09.309208Z"
    },
    "_kg_hide-input": true,
    "colab": {},
    "colab_type": "code",
    "id": "l9nfFTyj-KYY"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostClassifier, cv, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "D16Dquw1AAK0",
    "outputId": "44167587-f22e-4bf5-a816-e2bcfdc6c4ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " 'Bayesian_optimization_case_study.ipynb',\n",
       " 'flight_delays_test.csv.zip',\n",
       " 'flight_delays_train.csv.zip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T14:48:15.929012Z",
     "start_time": "2019-04-22T14:48:15.926574Z"
    },
    "colab_type": "text",
    "id": "AkBt3yds-KYu"
   },
   "source": [
    "## How does Bayesian optimization work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1kyBCUs-KYv"
   },
   "source": [
    "Bayesian optimization works by constructing a posterior distribution of functions (Gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not, as seen in the picture below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAdHF72R-KYw"
   },
   "source": [
    "<img src=\"https://github.com/fmfn/BayesianOptimization/blob/master/examples/bo_example.png?raw=true\" />\n",
    "As you iterate over and over, the algorithm balances its needs of exploration and exploitation while taking into account what it knows about the target function. At each step, a Gaussian Process is fitted to the known samples (points previously explored), and the posterior distribution, combined with an exploration strategy (such as UCB — aka Upper Confidence Bound), or EI (Expected Improvement). This process is used to determine the next point that should be explored (see the gif below).\n",
    "<img src=\"https://github.com/fmfn/BayesianOptimization/raw/master/examples/bayesian_optimization.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTP8KUlLoYzu"
   },
   "source": [
    "## Let's look at a simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crpPqKdC-KYx"
   },
   "source": [
    "The first step is to create an optimizer. It uses two items:\n",
    "* function to optimize\n",
    "* bounds of parameters\n",
    "\n",
    "The function is the procedure that counts metrics of our model quality. The important thing is that our optimization will maximize the value on function. Smaller metrics are best. Hint: don't forget to use negative metric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e09ciF8gpTfr"
   },
   "source": [
    "Here we define our simple function we want to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofwvnfEwo5mG"
   },
   "outputs": [],
   "source": [
    "def simple_func(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCGsdciCpeI3"
   },
   "source": [
    "Now, we define our bounds of the parameters to optimize, within the Bayesian optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jLYW2qnpOFr"
   },
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    simple_func,\n",
    "    {'a': (1, 3),\n",
    "    'b': (4, 7)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dg6LdYx8pq2T"
   },
   "source": [
    "These are the main parameters of this function:\n",
    "\n",
    "* **n_iter:** This is how many steps of Bayesian optimization you want to perform. The more steps, the more likely you are to find a good maximum.\n",
    "\n",
    "* **init_points:** This is how many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-GKMJ1uqMYv"
   },
   "source": [
    "Let's run an example where we use the optimizer to find the best values to maximize the target value for a and b given the inputs of 3 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Oy44Ro7wqNat",
    "outputId": "9cc64d54-b1e6-46d1-dc29-4c0039a1c72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     a     |     b     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m7.48     \u001b[0m | \u001b[0m1.807    \u001b[0m | \u001b[0m5.673    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m8.937    \u001b[0m | \u001b[95m2.711    \u001b[0m | \u001b[95m6.226    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m8.887    \u001b[0m | \u001b[0m2.105    \u001b[0m | \u001b[0m6.782    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m9.169    \u001b[0m | \u001b[95m2.54     \u001b[0m | \u001b[95m6.629    \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m7.0      \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyKFMF2Hq2Sx"
   },
   "source": [
    "Great, now let's print the best parameters and the associated maximized target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_H6DixyfscV_",
    "outputId": "fd0c35d7-e30d-4d30-9ab2-12c0fa837971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 3.0, 'b': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(optimizer.max['params']);optimizer.max['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQ1T1V6Mspi4"
   },
   "source": [
    "## Test it on real data using the Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_oGwREZkm4h"
   },
   "source": [
    "The dataset we will be working with is the famous flight departures dataset. Our modeling goal will be to predict if a flight departure is going to be delayed by 15 minutes based on the other attributes in our dataset. As part of this modeling exercise, we will use Bayesian hyperparameter optimization to identify the best parameters for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abYSagjQANDZ"
   },
   "source": [
    "**<font color='teal'> You can load the zipped csv files just as you would regular csv files using Pandas read_csv. In the next cell load the train and test data into two seperate dataframes. </font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWKBApVuAeJe"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('flight_delays_train.csv.zip')\n",
    "test_df = pd.read_csv('flight_delays_test.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OapNcT9Eikis"
   },
   "source": [
    "**<font color='teal'> Print the top five rows of the train dataframe and review the columns in the data. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "__4cXZ8iiYaC",
    "outputId": "8718ad4b-8955-486c-9ae8-1dee6aa6c2fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0   c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1   c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2   c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3  c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4  c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "\n",
       "  dep_delayed_15min  \n",
       "0                 N  \n",
       "1                 N  \n",
       "2                 N  \n",
       "3                 N  \n",
       "4                 Y  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxGBsPQhffgd"
   },
   "source": [
    "**<font color='teal'> Use the describe function to review the numeric columns in the train dataframe. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "_bRRKG3DAtae",
    "outputId": "7cfb9975-ec97-422c-abbd-98923a0b7aec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1341.523880</td>\n",
       "      <td>729.39716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>476.378445</td>\n",
       "      <td>574.61686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>931.000000</td>\n",
       "      <td>317.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1330.000000</td>\n",
       "      <td>575.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1733.000000</td>\n",
       "      <td>957.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2534.000000</td>\n",
       "      <td>4962.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DepTime      Distance\n",
       "count  100000.000000  100000.00000\n",
       "mean     1341.523880     729.39716\n",
       "std       476.378445     574.61686\n",
       "min         1.000000      30.00000\n",
       "25%       931.000000     317.00000\n",
       "50%      1330.000000     575.00000\n",
       "75%      1733.000000     957.00000\n",
       "max      2534.000000    4962.00000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6k-_fI5Aiyh"
   },
   "source": [
    "Notice, `DepTime` is the departure time in a numeric representation in 2400 hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtZS4-hrlQah"
   },
   "source": [
    " **<font color='teal'>The response variable is 'dep_delayed_15min' which is a categorical column, so we need to map the Y for yes and N for no values to 1 and 0. Run the code in the next cell to do this.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:38:42.677690Z",
     "start_time": "2019-04-22T15:38:42.481963Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yRlOTbnW-KYc"
   },
   "outputs": [],
   "source": [
    "#train_df = train_df[train_df.DepTime <= 2400].copy()\n",
    "y_train = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3WPkFQO9uo9"
   },
   "source": [
    "## Feature Engineering\n",
    "Use these defined functions to create additional features for the model. Run the cell to add the functions to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXqsqz5W9t3r"
   },
   "outputs": [],
   "source": [
    "def label_enc(df_column):\n",
    "    df_column = LabelEncoder().fit_transform(df_column)\n",
    "    return df_column\n",
    "\n",
    "def make_harmonic_features_sin(value, period=2400):\n",
    "    value *= 2 * np.pi / period \n",
    "    return np.sin(value)\n",
    "\n",
    "def make_harmonic_features_cos(value, period=2400):\n",
    "    value *= 2 * np.pi / period \n",
    "    return np.cos(value)\n",
    "\n",
    "def feature_eng(df):\n",
    "    df['flight'] = df['Origin']+df['Dest']\n",
    "    df['Month'] = df.Month.map(lambda x: x.split('-')[-1]).astype('int32')\n",
    "    df['DayofMonth'] = df.DayofMonth.map(lambda x: x.split('-')[-1]).astype('uint8')\n",
    "    df['begin_of_month'] = (df['DayofMonth'] < 10).astype('uint8')\n",
    "    df['midddle_of_month'] = ((df['DayofMonth'] >= 10)&(df['DayofMonth'] < 20)).astype('uint8')\n",
    "    df['end_of_month'] = (df['DayofMonth'] >= 20).astype('uint8')\n",
    "    df['DayOfWeek'] = df.DayOfWeek.map(lambda x: x.split('-')[-1]).astype('uint8')\n",
    "    df['hour'] = df.DepTime.map(lambda x: x/100).astype('int32')\n",
    "    df['morning'] = df['hour'].map(lambda x: 1 if (x <= 11)& (x >= 7) else 0).astype('uint8')\n",
    "    df['day'] = df['hour'].map(lambda x: 1 if (x >= 12) & (x <= 18) else 0).astype('uint8')\n",
    "    df['evening'] = df['hour'].map(lambda x: 1 if (x >= 19) & (x <= 23) else 0).astype('uint8')\n",
    "    df['night'] = df['hour'].map(lambda x: 1 if (x >= 0) & (x <= 6) else 0).astype('int32')\n",
    "    df['winter'] = df['Month'].map(lambda x: x in [12, 1, 2]).astype('int32')\n",
    "    df['spring'] = df['Month'].map(lambda x: x in [3, 4, 5]).astype('int32')\n",
    "    df['summer'] = df['Month'].map(lambda x: x in [6, 7, 8]).astype('int32')\n",
    "    df['autumn'] = df['Month'].map(lambda x: x in [9, 10, 11]).astype('int32')\n",
    "    df['holiday'] = (df['DayOfWeek'] >= 5).astype(int) \n",
    "    df['weekday'] = (df['DayOfWeek'] < 5).astype(int)\n",
    "    df['airport_dest_per_month'] = df.groupby(['Dest', 'Month'])['Dest'].transform('count')\n",
    "    df['airport_origin_per_month'] = df.groupby(['Origin', 'Month'])['Origin'].transform('count')\n",
    "    df['airport_dest_count'] = df.groupby(['Dest'])['Dest'].transform('count')\n",
    "    df['airport_origin_count'] = df.groupby(['Origin'])['Origin'].transform('count')\n",
    "    df['carrier_count'] = df.groupby(['UniqueCarrier'])['Dest'].transform('count')\n",
    "    df['carrier_count_per month'] = df.groupby(['UniqueCarrier', 'Month'])['Dest'].transform('count')\n",
    "    df['deptime_cos'] = df['DepTime'].map(make_harmonic_features_cos)\n",
    "    df['deptime_sin'] = df['DepTime'].map(make_harmonic_features_sin)\n",
    "    df['flightUC'] = df['flight']+df['UniqueCarrier']\n",
    "    df['DestUC'] = df['Dest']+df['UniqueCarrier']\n",
    "    df['OriginUC'] = df['Origin']+df['UniqueCarrier']\n",
    "    return df.drop('DepTime', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BYbxXpU-FGE"
   },
   "source": [
    "Concatenate the training and testing dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cj6bfSNw_RAf"
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df.drop('dep_delayed_15min', axis=1), test_df])\n",
    "full_df = feature_eng(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSO8JbfM_W-F"
   },
   "source": [
    "Apply the earlier defined feature engineering functions to the full dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6RfAINftjwi"
   },
   "outputs": [],
   "source": [
    "for column in ['UniqueCarrier', 'Origin', 'Dest','flight',  'flightUC', 'DestUC', 'OriginUC']:\n",
    "    full_df[column] = label_enc(full_df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJAw1RGB_ZuM"
   },
   "source": [
    "\n",
    "Split the new full dataframe into X_train and X_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15cPtQU5tjfz"
   },
   "outputs": [],
   "source": [
    "X_train = full_df[:train_df.shape[0]]\n",
    "X_test = full_df[train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umfAw-9JErLV"
   },
   "source": [
    "Create a list of the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T14:31:58.412296Z",
     "start_time": "2019-04-22T14:31:58.409088Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5ibeVyNb-KZI"
   },
   "outputs": [],
   "source": [
    "categorical_features = ['Month',  'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest','flight',  'flightUC', 'DestUC', 'OriginUC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzMIsMPIETVk"
   },
   "source": [
    "Let's build a light GBM model to test the bayesian optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:18:04.466965Z",
     "start_time": "2019-04-22T15:18:04.457992Z"
    },
    "colab_type": "text",
    "id": "2hfm1i5G-KZH"
   },
   "source": [
    "### [LightGBM](https://lightgbm.readthedocs.io/en/latest/) is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n",
    "\n",
    "* Faster training speed and higher efficiency.\n",
    "* Lower memory usage.\n",
    "* Better accuracy.\n",
    "* Support of parallel and GPU learning.\n",
    "* Capable of handling large-scale data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jf-3F2Wg-KZL"
   },
   "source": [
    "First, we define the function we want to maximize and that will count cross-validation metrics of lightGBM for our parameters.\n",
    "\n",
    "Some params such as num_leaves, max_depth, min_child_samples, min_data_in_leaf should be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:40:14.034265Z",
     "start_time": "2019-04-22T15:40:14.027868Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LyUJBhGX-KZM"
   },
   "outputs": [],
   "source": [
    "def lgb_eval(num_leaves,max_depth,lambda_l2,lambda_l1,min_child_samples, min_data_in_leaf):\n",
    "    params = {\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : \"auc\", \n",
    "        'is_unbalance': True,\n",
    "        \"num_leaves\" : int(num_leaves),\n",
    "        \"max_depth\" : int(max_depth),\n",
    "        \"lambda_l2\" : lambda_l2,\n",
    "        \"lambda_l1\" : lambda_l1,\n",
    "        \"num_threads\" : 20,\n",
    "        \"min_child_samples\" : int(min_child_samples),\n",
    "        'min_data_in_leaf': int(min_data_in_leaf),\n",
    "        \"learning_rate\" : 0.03,\n",
    "        \"subsample_freq\" : 5,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    lgtrain = lightgbm.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "    cv_result = lightgbm.cv(params,\n",
    "                       lgtrain,\n",
    "                       1000,\n",
    "                       callbacks=[lightgbm.early_stopping(stopping_rounds=100)],\n",
    "                       stratified=True,\n",
    "                       nfold=3)\n",
    "    return cv_result\n",
    "#['metric'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJwqBhdeF11Q"
   },
   "source": [
    "Apply the Bayesian optimizer to the function we created in the previous step to identify the best hyperparameters. We will run 10 iterations and set init_points = 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:48:04.682447Z",
     "start_time": "2019-04-22T15:40:14.641634Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JheCOkUE-KZP",
    "outputId": "8f37ee51-885d-44e4-cdcd-ceb7abd58b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tcv_agg's valid auc: 0.727848 + 0.00358629\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14016\\2623645567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                                 })\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mlgbBO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msuggest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutility_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_subscribers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\logger.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, event, instance)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mis_new_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_new_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_new_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\logger.py\u001b[0m in \u001b[0;36m_is_new_max\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_previous_max\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_previous_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_previous_max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (25, 4000),\n",
    "                                                'max_depth': (5, 63),\n",
    "                                                'lambda_l2': (0.0, 0.05),\n",
    "                                                'lambda_l1': (0.0, 0.05),\n",
    "                                                'min_child_samples': (50, 10000),\n",
    "                                                'min_data_in_leaf': (100, 2000)\n",
    "                                                })\n",
    "\n",
    "lgbBO.maximize(n_iter=10, init_points=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdkxhhST-KZS"
   },
   "source": [
    " **<font color='teal'> Print the best result by using the '.max' function.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:49:01.513767Z",
     "start_time": "2019-04-22T15:49:01.509392Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "oc8z6mfy-KZS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': {'valid auc-mean': [0.6993880692173525,\n",
       "   0.7055811098827757,\n",
       "   0.7087972558462147,\n",
       "   0.7109870743902462,\n",
       "   0.7131070214709552,\n",
       "   0.7139841361679006,\n",
       "   0.715029833301311,\n",
       "   0.7161273281293522,\n",
       "   0.716827152006776,\n",
       "   0.7176652581586022,\n",
       "   0.7182453979781531,\n",
       "   0.7184620870507775,\n",
       "   0.7187846899466294,\n",
       "   0.7193597921700651,\n",
       "   0.719459112029952,\n",
       "   0.719548257421017,\n",
       "   0.7199309291802636,\n",
       "   0.7201345574283543,\n",
       "   0.7202901680717604,\n",
       "   0.7205510293592243,\n",
       "   0.7207393831249794,\n",
       "   0.7208376195335476,\n",
       "   0.7210272483178057,\n",
       "   0.7211688728629149,\n",
       "   0.7211519832475558,\n",
       "   0.7212732185947303,\n",
       "   0.7214374645594185,\n",
       "   0.7214973216012242,\n",
       "   0.7216891721066054,\n",
       "   0.7217895503545159,\n",
       "   0.7218307620299834,\n",
       "   0.7220069952874376,\n",
       "   0.7220435377900957,\n",
       "   0.7221633526211845,\n",
       "   0.7222498140515397,\n",
       "   0.7223297963762945,\n",
       "   0.7224777917853861,\n",
       "   0.722552550809079,\n",
       "   0.7225768138395833,\n",
       "   0.7226487675300507,\n",
       "   0.7228399281815433,\n",
       "   0.7229561796424343,\n",
       "   0.7230305871443323,\n",
       "   0.7230235455281905,\n",
       "   0.722972630441343,\n",
       "   0.7229765920819743,\n",
       "   0.7230680193740268,\n",
       "   0.7230549551372544,\n",
       "   0.7231052421762475,\n",
       "   0.723087279638141,\n",
       "   0.7230573921452402,\n",
       "   0.7231293476151065,\n",
       "   0.7231760699891382,\n",
       "   0.7232515257678113,\n",
       "   0.7232897533351856,\n",
       "   0.7233204735413216,\n",
       "   0.723280192155384,\n",
       "   0.7234020414988819,\n",
       "   0.7235478148204718,\n",
       "   0.7236929634896089,\n",
       "   0.7237581998444974,\n",
       "   0.723825416239173,\n",
       "   0.723861777571225,\n",
       "   0.7239765903912868,\n",
       "   0.7240728522526819,\n",
       "   0.7241342906874398,\n",
       "   0.7241228320768484,\n",
       "   0.7241695423768273,\n",
       "   0.724233266321917,\n",
       "   0.7242935624268534,\n",
       "   0.7243816402454449,\n",
       "   0.7244480968366567,\n",
       "   0.7244919538824467,\n",
       "   0.7245605826857568,\n",
       "   0.7246542160695434,\n",
       "   0.724692805645173,\n",
       "   0.724754372788022,\n",
       "   0.7248428521214193,\n",
       "   0.7249535960376594,\n",
       "   0.7249952586934766,\n",
       "   0.7251357240112556,\n",
       "   0.7251735885570469,\n",
       "   0.7251736425380032,\n",
       "   0.7252174668034014,\n",
       "   0.7252918416575133,\n",
       "   0.7253352627680189,\n",
       "   0.7254310422346064,\n",
       "   0.7255248160795499,\n",
       "   0.7255925539765765,\n",
       "   0.7256678205439279,\n",
       "   0.7257098828212222,\n",
       "   0.7257272590552346,\n",
       "   0.7257368391898823,\n",
       "   0.7257664227810107,\n",
       "   0.7258204181767219,\n",
       "   0.7258611024160343,\n",
       "   0.7258542690487676,\n",
       "   0.725900210831551,\n",
       "   0.7259523151388745,\n",
       "   0.7259569582446156,\n",
       "   0.7259992252658883,\n",
       "   0.7259724698621205,\n",
       "   0.7260384729811253,\n",
       "   0.7260630357727326,\n",
       "   0.7261324236093977,\n",
       "   0.7261259399565855,\n",
       "   0.7261445855863324,\n",
       "   0.7261601539139934,\n",
       "   0.7261677550274094,\n",
       "   0.7262296999388137,\n",
       "   0.7262866449453091,\n",
       "   0.7262897134442139,\n",
       "   0.7263311484404821,\n",
       "   0.7263769019371921,\n",
       "   0.7263854735671513,\n",
       "   0.7264479261189104,\n",
       "   0.7264315799977029,\n",
       "   0.7264178257427808,\n",
       "   0.7264770938902799,\n",
       "   0.7264786953626677,\n",
       "   0.7264665244342267,\n",
       "   0.7265134257254666,\n",
       "   0.7265575128521782,\n",
       "   0.726561428426525,\n",
       "   0.7265384385723194,\n",
       "   0.7265483708057308,\n",
       "   0.7266064247383216,\n",
       "   0.7267472387163424,\n",
       "   0.7268313553134278,\n",
       "   0.7268957095386422,\n",
       "   0.7268907764164517,\n",
       "   0.7269038084345864,\n",
       "   0.7269271377480351,\n",
       "   0.7270021808030322,\n",
       "   0.7269774661012436,\n",
       "   0.7270150257204699,\n",
       "   0.7269907859857238,\n",
       "   0.7269524582592335,\n",
       "   0.7269502140629003,\n",
       "   0.7270015103803323,\n",
       "   0.7269674731580854,\n",
       "   0.7269461954681011,\n",
       "   0.7269494624766355,\n",
       "   0.7269691371401694,\n",
       "   0.7270088163076908,\n",
       "   0.7270530899873702,\n",
       "   0.7270777547395927,\n",
       "   0.7271046164297094,\n",
       "   0.7271398174653282,\n",
       "   0.7271713778047854,\n",
       "   0.7271899570009585,\n",
       "   0.7272390460409194,\n",
       "   0.727281874940855,\n",
       "   0.7272609431809753,\n",
       "   0.7272797855875348,\n",
       "   0.7273663417368136,\n",
       "   0.7273728374803353,\n",
       "   0.7273887259501249,\n",
       "   0.727452990329157,\n",
       "   0.7274763512136097,\n",
       "   0.7274841803564507,\n",
       "   0.7275201467720088,\n",
       "   0.7275074516985821,\n",
       "   0.7275387071104645,\n",
       "   0.7276087730099157,\n",
       "   0.7276268993350063,\n",
       "   0.7276468924188123,\n",
       "   0.727626356675608,\n",
       "   0.7276149635094908,\n",
       "   0.7276284656645418,\n",
       "   0.7276134030500164,\n",
       "   0.7276337823113471,\n",
       "   0.7276530525787287,\n",
       "   0.7277088092632084,\n",
       "   0.7277129775167744,\n",
       "   0.7276811337112642,\n",
       "   0.7276696361610681,\n",
       "   0.7276780691824584,\n",
       "   0.7276642827805011,\n",
       "   0.7276703582793468,\n",
       "   0.7276905941221002,\n",
       "   0.727697515789563,\n",
       "   0.7277080605067332,\n",
       "   0.727740151954532,\n",
       "   0.727735524627659,\n",
       "   0.7277114210200439,\n",
       "   0.7277039784004473,\n",
       "   0.7276754905932322,\n",
       "   0.7277195534881934,\n",
       "   0.7277352353738195,\n",
       "   0.7277682706398272,\n",
       "   0.7278346310472498,\n",
       "   0.7278350763195278,\n",
       "   0.7278477904000785],\n",
       "  'valid auc-stdv': [0.005577642194376592,\n",
       "   0.0040836761439231655,\n",
       "   0.0055580408573017446,\n",
       "   0.0058230598971390265,\n",
       "   0.005677463105998461,\n",
       "   0.005557029527932907,\n",
       "   0.005137860247154888,\n",
       "   0.005007477582243946,\n",
       "   0.005123105420920135,\n",
       "   0.005281667902890354,\n",
       "   0.005188317694065211,\n",
       "   0.005197895847419756,\n",
       "   0.005338825969934555,\n",
       "   0.005243765562173435,\n",
       "   0.0050294247420852615,\n",
       "   0.00517847567787341,\n",
       "   0.005243112717274336,\n",
       "   0.005222974326921875,\n",
       "   0.005189634033327583,\n",
       "   0.005096847355399695,\n",
       "   0.0051340726592050126,\n",
       "   0.005158606841829282,\n",
       "   0.00511921610681658,\n",
       "   0.005016456355996626,\n",
       "   0.0050950821144491116,\n",
       "   0.0050386976794335545,\n",
       "   0.005078672616948492,\n",
       "   0.005028595240925789,\n",
       "   0.005030077407422799,\n",
       "   0.004912472028674861,\n",
       "   0.004789538117018508,\n",
       "   0.004864356065023401,\n",
       "   0.004778622033411736,\n",
       "   0.004832806790169145,\n",
       "   0.004901400275897741,\n",
       "   0.004886088917581981,\n",
       "   0.004829274194378959,\n",
       "   0.004849453186604424,\n",
       "   0.004777289554638576,\n",
       "   0.004719221393627681,\n",
       "   0.004639898890370328,\n",
       "   0.004639513842754522,\n",
       "   0.004621814737218741,\n",
       "   0.004625438874053433,\n",
       "   0.004693953253056758,\n",
       "   0.004651622474075751,\n",
       "   0.004607662773967,\n",
       "   0.00458027285986434,\n",
       "   0.0046112971239058685,\n",
       "   0.004615237065955362,\n",
       "   0.0046671401762310065,\n",
       "   0.004586020039602466,\n",
       "   0.004577859790805071,\n",
       "   0.0045783703946181255,\n",
       "   0.004563328400396312,\n",
       "   0.004574519729549133,\n",
       "   0.004574911693731352,\n",
       "   0.004588395582222825,\n",
       "   0.004556832370056663,\n",
       "   0.004540705468335149,\n",
       "   0.004482805858031262,\n",
       "   0.004476247985156175,\n",
       "   0.004438952837127034,\n",
       "   0.004409740221074191,\n",
       "   0.004433714570398,\n",
       "   0.004470962098167475,\n",
       "   0.0044334347401930345,\n",
       "   0.004451795360361166,\n",
       "   0.004538026333674111,\n",
       "   0.004559652303085111,\n",
       "   0.00464082711951733,\n",
       "   0.004697667795322829,\n",
       "   0.004702321332548618,\n",
       "   0.004750876511414351,\n",
       "   0.004734996189607222,\n",
       "   0.00478502642214465,\n",
       "   0.004721546399836742,\n",
       "   0.004693961828818254,\n",
       "   0.0047191188719608035,\n",
       "   0.00474773578211223,\n",
       "   0.004728205811228088,\n",
       "   0.0047338311239772494,\n",
       "   0.004763232926016835,\n",
       "   0.004798240987168897,\n",
       "   0.004849439104462109,\n",
       "   0.0047937658993673455,\n",
       "   0.004810495764573158,\n",
       "   0.004821662888108873,\n",
       "   0.004799072209285969,\n",
       "   0.004787345854527155,\n",
       "   0.004756996302640158,\n",
       "   0.004721311098914379,\n",
       "   0.004689482008161495,\n",
       "   0.004650142513546419,\n",
       "   0.004617218479586336,\n",
       "   0.0046150412162796785,\n",
       "   0.004584848646770584,\n",
       "   0.004589880232045873,\n",
       "   0.004599264671987602,\n",
       "   0.0045860080947519016,\n",
       "   0.004592550179192816,\n",
       "   0.00457315350856316,\n",
       "   0.0045647275163825185,\n",
       "   0.004497078432580591,\n",
       "   0.004500473285047401,\n",
       "   0.004496749987228248,\n",
       "   0.004477198103887392,\n",
       "   0.004506080933798354,\n",
       "   0.0045285415497329186,\n",
       "   0.004477977986288464,\n",
       "   0.004419515015012498,\n",
       "   0.004428522064040974,\n",
       "   0.004447900410776374,\n",
       "   0.00444452576961326,\n",
       "   0.004435102454819319,\n",
       "   0.004441110472651104,\n",
       "   0.004432704509162928,\n",
       "   0.0044218616579764355,\n",
       "   0.00436412266003415,\n",
       "   0.004298403495948183,\n",
       "   0.004262675124185946,\n",
       "   0.004261567879480662,\n",
       "   0.004287677477551751,\n",
       "   0.004259570793613159,\n",
       "   0.004221436157438536,\n",
       "   0.004188551225749295,\n",
       "   0.004143822369764491,\n",
       "   0.004082170864201432,\n",
       "   0.004053095686406276,\n",
       "   0.004029017156236278,\n",
       "   0.0040477437346068314,\n",
       "   0.004014760600354365,\n",
       "   0.00399783481083005,\n",
       "   0.003967122527538842,\n",
       "   0.0039767455158762404,\n",
       "   0.003952474190536159,\n",
       "   0.0039547438866021165,\n",
       "   0.003948789841089437,\n",
       "   0.003927336387028136,\n",
       "   0.0038578682702514236,\n",
       "   0.0038602878040244278,\n",
       "   0.0038365080943997994,\n",
       "   0.0038427529915952725,\n",
       "   0.003844822498276679,\n",
       "   0.0038492548712389186,\n",
       "   0.0038898739815426317,\n",
       "   0.003842176365685939,\n",
       "   0.003790926462797006,\n",
       "   0.0037777136334343165,\n",
       "   0.003763078717268275,\n",
       "   0.003762101740215892,\n",
       "   0.003730105765141859,\n",
       "   0.0037140897144232587,\n",
       "   0.003715635140724913,\n",
       "   0.003685534442541443,\n",
       "   0.003690883877784535,\n",
       "   0.0036667086282035476,\n",
       "   0.0036438930658378855,\n",
       "   0.003640346775837481,\n",
       "   0.0036016524788625515,\n",
       "   0.0036641917967296074,\n",
       "   0.0036137556061055414,\n",
       "   0.0036257734161732505,\n",
       "   0.0035793176810183748,\n",
       "   0.0035272092332988302,\n",
       "   0.003551792662541193,\n",
       "   0.003593252822152423,\n",
       "   0.0036470390390134495,\n",
       "   0.003652539419026477,\n",
       "   0.0036658806802449214,\n",
       "   0.003642691022335155,\n",
       "   0.0036331587191570118,\n",
       "   0.0036182382364401506,\n",
       "   0.0036414934623122696,\n",
       "   0.003632975407797199,\n",
       "   0.00361355248024375,\n",
       "   0.0035828687389643666,\n",
       "   0.003604654683400343,\n",
       "   0.0035990365345426405,\n",
       "   0.003683762759696981,\n",
       "   0.003638424173596048,\n",
       "   0.0036268081343871347,\n",
       "   0.0036273709882909877,\n",
       "   0.003620781095576083,\n",
       "   0.003624238070466074,\n",
       "   0.0036291298962136224,\n",
       "   0.003611760282223124,\n",
       "   0.0036262993735056213,\n",
       "   0.0035892669303834944,\n",
       "   0.0035860942588886715,\n",
       "   0.00357549621756604,\n",
       "   0.0035507534869506437,\n",
       "   0.0035706190352075805,\n",
       "   0.0035862907286413194]},\n",
       " 'params': {'lambda_l1': 0.04877244156043521,\n",
       "  'lambda_l2': 0.03569563975322295,\n",
       "  'max_depth': 61.470008673583436,\n",
       "  'min_child_samples': 1098.222465154405,\n",
       "  'min_data_in_leaf': 819.3782806519183,\n",
       "  'num_leaves': 3115.39594303878}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:50:29.049881Z",
     "start_time": "2019-04-22T15:50:29.045908Z"
    },
    "colab_type": "text",
    "id": "J5LAydKC-KZW"
   },
   "source": [
    "Review the process at each step by using the '.res[0]' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:51:01.001688Z",
     "start_time": "2019-04-22T15:51:00.997484Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "X1ttZmrI-KZX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': {'valid auc-mean': [0.6993880692173525,\n",
       "   0.7055811098827757,\n",
       "   0.7087972558462147,\n",
       "   0.7109870743902462,\n",
       "   0.7131070214709552,\n",
       "   0.7139841361679006,\n",
       "   0.715029833301311,\n",
       "   0.7161273281293522,\n",
       "   0.716827152006776,\n",
       "   0.7176652581586022,\n",
       "   0.7182453979781531,\n",
       "   0.7184620870507775,\n",
       "   0.7187846899466294,\n",
       "   0.7193597921700651,\n",
       "   0.719459112029952,\n",
       "   0.719548257421017,\n",
       "   0.7199309291802636,\n",
       "   0.7201345574283543,\n",
       "   0.7202901680717604,\n",
       "   0.7205510293592243,\n",
       "   0.7207393831249794,\n",
       "   0.7208376195335476,\n",
       "   0.7210272483178057,\n",
       "   0.7211688728629149,\n",
       "   0.7211519832475558,\n",
       "   0.7212732185947303,\n",
       "   0.7214374645594185,\n",
       "   0.7214973216012242,\n",
       "   0.7216891721066054,\n",
       "   0.7217895503545159,\n",
       "   0.7218307620299834,\n",
       "   0.7220069952874376,\n",
       "   0.7220435377900957,\n",
       "   0.7221633526211845,\n",
       "   0.7222498140515397,\n",
       "   0.7223297963762945,\n",
       "   0.7224777917853861,\n",
       "   0.722552550809079,\n",
       "   0.7225768138395833,\n",
       "   0.7226487675300507,\n",
       "   0.7228399281815433,\n",
       "   0.7229561796424343,\n",
       "   0.7230305871443323,\n",
       "   0.7230235455281905,\n",
       "   0.722972630441343,\n",
       "   0.7229765920819743,\n",
       "   0.7230680193740268,\n",
       "   0.7230549551372544,\n",
       "   0.7231052421762475,\n",
       "   0.723087279638141,\n",
       "   0.7230573921452402,\n",
       "   0.7231293476151065,\n",
       "   0.7231760699891382,\n",
       "   0.7232515257678113,\n",
       "   0.7232897533351856,\n",
       "   0.7233204735413216,\n",
       "   0.723280192155384,\n",
       "   0.7234020414988819,\n",
       "   0.7235478148204718,\n",
       "   0.7236929634896089,\n",
       "   0.7237581998444974,\n",
       "   0.723825416239173,\n",
       "   0.723861777571225,\n",
       "   0.7239765903912868,\n",
       "   0.7240728522526819,\n",
       "   0.7241342906874398,\n",
       "   0.7241228320768484,\n",
       "   0.7241695423768273,\n",
       "   0.724233266321917,\n",
       "   0.7242935624268534,\n",
       "   0.7243816402454449,\n",
       "   0.7244480968366567,\n",
       "   0.7244919538824467,\n",
       "   0.7245605826857568,\n",
       "   0.7246542160695434,\n",
       "   0.724692805645173,\n",
       "   0.724754372788022,\n",
       "   0.7248428521214193,\n",
       "   0.7249535960376594,\n",
       "   0.7249952586934766,\n",
       "   0.7251357240112556,\n",
       "   0.7251735885570469,\n",
       "   0.7251736425380032,\n",
       "   0.7252174668034014,\n",
       "   0.7252918416575133,\n",
       "   0.7253352627680189,\n",
       "   0.7254310422346064,\n",
       "   0.7255248160795499,\n",
       "   0.7255925539765765,\n",
       "   0.7256678205439279,\n",
       "   0.7257098828212222,\n",
       "   0.7257272590552346,\n",
       "   0.7257368391898823,\n",
       "   0.7257664227810107,\n",
       "   0.7258204181767219,\n",
       "   0.7258611024160343,\n",
       "   0.7258542690487676,\n",
       "   0.725900210831551,\n",
       "   0.7259523151388745,\n",
       "   0.7259569582446156,\n",
       "   0.7259992252658883,\n",
       "   0.7259724698621205,\n",
       "   0.7260384729811253,\n",
       "   0.7260630357727326,\n",
       "   0.7261324236093977,\n",
       "   0.7261259399565855,\n",
       "   0.7261445855863324,\n",
       "   0.7261601539139934,\n",
       "   0.7261677550274094,\n",
       "   0.7262296999388137,\n",
       "   0.7262866449453091,\n",
       "   0.7262897134442139,\n",
       "   0.7263311484404821,\n",
       "   0.7263769019371921,\n",
       "   0.7263854735671513,\n",
       "   0.7264479261189104,\n",
       "   0.7264315799977029,\n",
       "   0.7264178257427808,\n",
       "   0.7264770938902799,\n",
       "   0.7264786953626677,\n",
       "   0.7264665244342267,\n",
       "   0.7265134257254666,\n",
       "   0.7265575128521782,\n",
       "   0.726561428426525,\n",
       "   0.7265384385723194,\n",
       "   0.7265483708057308,\n",
       "   0.7266064247383216,\n",
       "   0.7267472387163424,\n",
       "   0.7268313553134278,\n",
       "   0.7268957095386422,\n",
       "   0.7268907764164517,\n",
       "   0.7269038084345864,\n",
       "   0.7269271377480351,\n",
       "   0.7270021808030322,\n",
       "   0.7269774661012436,\n",
       "   0.7270150257204699,\n",
       "   0.7269907859857238,\n",
       "   0.7269524582592335,\n",
       "   0.7269502140629003,\n",
       "   0.7270015103803323,\n",
       "   0.7269674731580854,\n",
       "   0.7269461954681011,\n",
       "   0.7269494624766355,\n",
       "   0.7269691371401694,\n",
       "   0.7270088163076908,\n",
       "   0.7270530899873702,\n",
       "   0.7270777547395927,\n",
       "   0.7271046164297094,\n",
       "   0.7271398174653282,\n",
       "   0.7271713778047854,\n",
       "   0.7271899570009585,\n",
       "   0.7272390460409194,\n",
       "   0.727281874940855,\n",
       "   0.7272609431809753,\n",
       "   0.7272797855875348,\n",
       "   0.7273663417368136,\n",
       "   0.7273728374803353,\n",
       "   0.7273887259501249,\n",
       "   0.727452990329157,\n",
       "   0.7274763512136097,\n",
       "   0.7274841803564507,\n",
       "   0.7275201467720088,\n",
       "   0.7275074516985821,\n",
       "   0.7275387071104645,\n",
       "   0.7276087730099157,\n",
       "   0.7276268993350063,\n",
       "   0.7276468924188123,\n",
       "   0.727626356675608,\n",
       "   0.7276149635094908,\n",
       "   0.7276284656645418,\n",
       "   0.7276134030500164,\n",
       "   0.7276337823113471,\n",
       "   0.7276530525787287,\n",
       "   0.7277088092632084,\n",
       "   0.7277129775167744,\n",
       "   0.7276811337112642,\n",
       "   0.7276696361610681,\n",
       "   0.7276780691824584,\n",
       "   0.7276642827805011,\n",
       "   0.7276703582793468,\n",
       "   0.7276905941221002,\n",
       "   0.727697515789563,\n",
       "   0.7277080605067332,\n",
       "   0.727740151954532,\n",
       "   0.727735524627659,\n",
       "   0.7277114210200439,\n",
       "   0.7277039784004473,\n",
       "   0.7276754905932322,\n",
       "   0.7277195534881934,\n",
       "   0.7277352353738195,\n",
       "   0.7277682706398272,\n",
       "   0.7278346310472498,\n",
       "   0.7278350763195278,\n",
       "   0.7278477904000785],\n",
       "  'valid auc-stdv': [0.005577642194376592,\n",
       "   0.0040836761439231655,\n",
       "   0.0055580408573017446,\n",
       "   0.0058230598971390265,\n",
       "   0.005677463105998461,\n",
       "   0.005557029527932907,\n",
       "   0.005137860247154888,\n",
       "   0.005007477582243946,\n",
       "   0.005123105420920135,\n",
       "   0.005281667902890354,\n",
       "   0.005188317694065211,\n",
       "   0.005197895847419756,\n",
       "   0.005338825969934555,\n",
       "   0.005243765562173435,\n",
       "   0.0050294247420852615,\n",
       "   0.00517847567787341,\n",
       "   0.005243112717274336,\n",
       "   0.005222974326921875,\n",
       "   0.005189634033327583,\n",
       "   0.005096847355399695,\n",
       "   0.0051340726592050126,\n",
       "   0.005158606841829282,\n",
       "   0.00511921610681658,\n",
       "   0.005016456355996626,\n",
       "   0.0050950821144491116,\n",
       "   0.0050386976794335545,\n",
       "   0.005078672616948492,\n",
       "   0.005028595240925789,\n",
       "   0.005030077407422799,\n",
       "   0.004912472028674861,\n",
       "   0.004789538117018508,\n",
       "   0.004864356065023401,\n",
       "   0.004778622033411736,\n",
       "   0.004832806790169145,\n",
       "   0.004901400275897741,\n",
       "   0.004886088917581981,\n",
       "   0.004829274194378959,\n",
       "   0.004849453186604424,\n",
       "   0.004777289554638576,\n",
       "   0.004719221393627681,\n",
       "   0.004639898890370328,\n",
       "   0.004639513842754522,\n",
       "   0.004621814737218741,\n",
       "   0.004625438874053433,\n",
       "   0.004693953253056758,\n",
       "   0.004651622474075751,\n",
       "   0.004607662773967,\n",
       "   0.00458027285986434,\n",
       "   0.0046112971239058685,\n",
       "   0.004615237065955362,\n",
       "   0.0046671401762310065,\n",
       "   0.004586020039602466,\n",
       "   0.004577859790805071,\n",
       "   0.0045783703946181255,\n",
       "   0.004563328400396312,\n",
       "   0.004574519729549133,\n",
       "   0.004574911693731352,\n",
       "   0.004588395582222825,\n",
       "   0.004556832370056663,\n",
       "   0.004540705468335149,\n",
       "   0.004482805858031262,\n",
       "   0.004476247985156175,\n",
       "   0.004438952837127034,\n",
       "   0.004409740221074191,\n",
       "   0.004433714570398,\n",
       "   0.004470962098167475,\n",
       "   0.0044334347401930345,\n",
       "   0.004451795360361166,\n",
       "   0.004538026333674111,\n",
       "   0.004559652303085111,\n",
       "   0.00464082711951733,\n",
       "   0.004697667795322829,\n",
       "   0.004702321332548618,\n",
       "   0.004750876511414351,\n",
       "   0.004734996189607222,\n",
       "   0.00478502642214465,\n",
       "   0.004721546399836742,\n",
       "   0.004693961828818254,\n",
       "   0.0047191188719608035,\n",
       "   0.00474773578211223,\n",
       "   0.004728205811228088,\n",
       "   0.0047338311239772494,\n",
       "   0.004763232926016835,\n",
       "   0.004798240987168897,\n",
       "   0.004849439104462109,\n",
       "   0.0047937658993673455,\n",
       "   0.004810495764573158,\n",
       "   0.004821662888108873,\n",
       "   0.004799072209285969,\n",
       "   0.004787345854527155,\n",
       "   0.004756996302640158,\n",
       "   0.004721311098914379,\n",
       "   0.004689482008161495,\n",
       "   0.004650142513546419,\n",
       "   0.004617218479586336,\n",
       "   0.0046150412162796785,\n",
       "   0.004584848646770584,\n",
       "   0.004589880232045873,\n",
       "   0.004599264671987602,\n",
       "   0.0045860080947519016,\n",
       "   0.004592550179192816,\n",
       "   0.00457315350856316,\n",
       "   0.0045647275163825185,\n",
       "   0.004497078432580591,\n",
       "   0.004500473285047401,\n",
       "   0.004496749987228248,\n",
       "   0.004477198103887392,\n",
       "   0.004506080933798354,\n",
       "   0.0045285415497329186,\n",
       "   0.004477977986288464,\n",
       "   0.004419515015012498,\n",
       "   0.004428522064040974,\n",
       "   0.004447900410776374,\n",
       "   0.00444452576961326,\n",
       "   0.004435102454819319,\n",
       "   0.004441110472651104,\n",
       "   0.004432704509162928,\n",
       "   0.0044218616579764355,\n",
       "   0.00436412266003415,\n",
       "   0.004298403495948183,\n",
       "   0.004262675124185946,\n",
       "   0.004261567879480662,\n",
       "   0.004287677477551751,\n",
       "   0.004259570793613159,\n",
       "   0.004221436157438536,\n",
       "   0.004188551225749295,\n",
       "   0.004143822369764491,\n",
       "   0.004082170864201432,\n",
       "   0.004053095686406276,\n",
       "   0.004029017156236278,\n",
       "   0.0040477437346068314,\n",
       "   0.004014760600354365,\n",
       "   0.00399783481083005,\n",
       "   0.003967122527538842,\n",
       "   0.0039767455158762404,\n",
       "   0.003952474190536159,\n",
       "   0.0039547438866021165,\n",
       "   0.003948789841089437,\n",
       "   0.003927336387028136,\n",
       "   0.0038578682702514236,\n",
       "   0.0038602878040244278,\n",
       "   0.0038365080943997994,\n",
       "   0.0038427529915952725,\n",
       "   0.003844822498276679,\n",
       "   0.0038492548712389186,\n",
       "   0.0038898739815426317,\n",
       "   0.003842176365685939,\n",
       "   0.003790926462797006,\n",
       "   0.0037777136334343165,\n",
       "   0.003763078717268275,\n",
       "   0.003762101740215892,\n",
       "   0.003730105765141859,\n",
       "   0.0037140897144232587,\n",
       "   0.003715635140724913,\n",
       "   0.003685534442541443,\n",
       "   0.003690883877784535,\n",
       "   0.0036667086282035476,\n",
       "   0.0036438930658378855,\n",
       "   0.003640346775837481,\n",
       "   0.0036016524788625515,\n",
       "   0.0036641917967296074,\n",
       "   0.0036137556061055414,\n",
       "   0.0036257734161732505,\n",
       "   0.0035793176810183748,\n",
       "   0.0035272092332988302,\n",
       "   0.003551792662541193,\n",
       "   0.003593252822152423,\n",
       "   0.0036470390390134495,\n",
       "   0.003652539419026477,\n",
       "   0.0036658806802449214,\n",
       "   0.003642691022335155,\n",
       "   0.0036331587191570118,\n",
       "   0.0036182382364401506,\n",
       "   0.0036414934623122696,\n",
       "   0.003632975407797199,\n",
       "   0.00361355248024375,\n",
       "   0.0035828687389643666,\n",
       "   0.003604654683400343,\n",
       "   0.0035990365345426405,\n",
       "   0.003683762759696981,\n",
       "   0.003638424173596048,\n",
       "   0.0036268081343871347,\n",
       "   0.0036273709882909877,\n",
       "   0.003620781095576083,\n",
       "   0.003624238070466074,\n",
       "   0.0036291298962136224,\n",
       "   0.003611760282223124,\n",
       "   0.0036262993735056213,\n",
       "   0.0035892669303834944,\n",
       "   0.0035860942588886715,\n",
       "   0.00357549621756604,\n",
       "   0.0035507534869506437,\n",
       "   0.0035706190352075805,\n",
       "   0.0035862907286413194]},\n",
       " 'params': {'lambda_l1': 0.04877244156043521,\n",
       "  'lambda_l2': 0.03569563975322295,\n",
       "  'max_depth': 61.470008673583436,\n",
       "  'min_child_samples': 1098.222465154405,\n",
       "  'min_data_in_leaf': 819.3782806519183,\n",
       "  'num_leaves': 3115.39594303878}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bayesian_optimization_exercise.ipynb",
   "provenance": []
  },
  "deepnote_execution_queue": [],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
